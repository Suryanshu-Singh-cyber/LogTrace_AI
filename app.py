import streamlit as st
import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
import seaborn as sns

# ======================================================
# PAGE CONFIG
# ======================================================
st.set_page_config(
    page_title="LogTrace AI | SOC DFIR Platform",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# ======================================================
# CYBER UI STYLE + ANIMATION
# ======================================================
st.markdown("""
<style>
body { background-color: #0b0f19; color: #e5e7eb; }
h1, h2, h3 { color: #38bdf8; }
.card {
    background: linear-gradient(145deg, #0f172a, #020617);
    padding: 18px;
    border-radius: 14px;
    box-shadow: 0 0 20px rgba(56,189,248,0.15);
    transition: transform 0.3s ease;
}
.card:hover { transform: scale(1.02); }
.icon { font-size: 28px; }
</style>
""", unsafe_allow_html=True)

st.title("üõ°Ô∏è LogTrace AI")
st.caption("Court-Defensible Digital Forensics & SOC Intelligence Platform")
st.markdown("---")

# ======================================================
# TABS
# ======================================================
tabs = st.tabs([
    "üì• Evidence Intake",
    "üß† AI Correlation",
    "üß™ Anti-Forensics",
    "üìä Risk & Confidence",
    "üßæ Reports",
    "üõ∞Ô∏è SIEM / SOC Integration"
])

# ======================================================
# TAB 1 ‚Äî EVIDENCE
# ======================================================
with tabs[0]:
    st.subheader("üì• Evidence Intake")

    mft_file = st.file_uploader("MFT CSV", type="csv")
    usn_file = st.file_uploader("USN Journal CSV", type="csv")
    log_file = st.file_uploader("Event Logs CSV", type="csv")

    if not (mft_file and usn_file and log_file):
        st.warning("Upload all artifacts to continue")
        st.stop()

    mft = pd.read_csv(mft_file, parse_dates=["modified"])
    usn = pd.read_csv(usn_file, parse_dates=["usn_timestamp"])
    logs = pd.read_csv(log_file, parse_dates=["timestamp"])

    st.success("‚úî Evidence loaded successfully")

# ======================================================
# TAB 2 ‚Äî AI CORRELATION
# ======================================================
with tabs[1]:
    st.subheader("üß† AI Timeline Correlation")

    deltas = []
    findings = []

    for _, m in mft.iterrows():
        related = usn[usn["filename"] == m["filename"]]
        for _, u in related.iterrows():
            delta = abs((u["usn_timestamp"] - m["modified"]).total_seconds()) / 3600
            deltas.append(delta)
            if delta > 24:
                findings.append(m["filename"])

    ai_conf = 0
    if len(deltas) >= 3:
        model = IsolationForest(contamination=0.25, random_state=42)
        model.fit(np.array(deltas).reshape(-1, 1))
        ai_conf = round((1 - np.mean(model.decision_function(np.array(deltas).reshape(-1, 1)))) * 100, 2)

    log_clear = logs[logs["event_id"].isin([1102, 104])]

    st.metric("AI Anomaly Confidence", f"{ai_conf}%")
    st.metric("Timestamp Manipulation Files", len(set(findings)))
    st.metric("Log Clearing Events", len(log_clear))

# ======================================================
# TAB 3 ‚Äî ANTI-FORENSICS
# ======================================================
with tabs[2]:
    st.subheader("üß™ Anti-Forensics Tool Scanner")

    SAMPLE = """artifact_type,artifact_name,timestamp
prefetch,CCLEANER.EXE,2024-10-12
prefetch,SDELETE.EXE,2024-10-13
registry,HKCU\\Software\\Piriform,2024-10-12
"""

    st.download_button("‚¨á Sample Artifact CSV", SAMPLE, "artifacts.csv")

    art_file = st.file_uploader("Upload Artifact CSV", type="csv")

    tools = ["CCLEANER.EXE", "SDELETE.EXE", "VERACRYPT.EXE", "BLEACHBIT.EXE"]

    detected = pd.DataFrame()
    if art_file:
        artifacts = pd.read_csv(art_file)
        detected = artifacts[artifacts["artifact_name"].isin(tools)]

        if not detected.empty:
            st.error("üö® Anti-Forensics Tools Detected")
            st.dataframe(detected)
        else:
            st.success("No wiping tools detected")

# ======================================================
# TAB 4 ‚Äî RISK & HEATMAP
# ======================================================
with tabs[3]:
    st.subheader("üî• Risk Heatmap")

    heatmap_data = pd.DataFrame({
        "Filesystem": [80 if findings else 20],
        "Event Logs": [70 if not log_clear.empty else 10],
        "Anti-Forensics": [90 if not detected.empty else 10]
    }, index=["Threat Level"])

    fig, ax = plt.subplots()
    sns.heatmap(heatmap_data, annot=True, cmap="Reds", ax=ax)
    st.pyplot(fig)

    st.markdown("### üìà Investigation Confidence Breakdown")

    conf = {
        "Filesystem Correlation": 80 if findings else 30,
        "Log Integrity": 70 if not log_clear.empty else 20,
        "Tool Detection": 90 if not detected.empty else 10,
        "AI Model Confidence": ai_conf
    }

    fig2, ax2 = plt.subplots()
    ax2.bar(conf.keys(), conf.values())
    ax2.set_ylim(0, 100)
    st.pyplot(fig2)

# ======================================================
# TAB 5 ‚Äî REPORTS
# ======================================================
with tabs[4]:
    st.subheader("üßæ Court-Style Executive Report")

    risk = "HIGH" if ai_conf > 65 else "MEDIUM" if ai_conf > 35 else "LOW"

    report = f"""
    Digital forensic analysis identified a {risk.lower()} probability of deliberate
    anti-forensic activity. Independent NTFS artifacts revealed timestamp anomalies
    inconsistent with normal system behavior.

    Log analysis indicates potential log-clearing behavior. Detected tool artifacts
    align with known data wiping and forensic evasion utilities.

    Conclusions are supported through statistical anomaly detection and artifact
    correlation methodologies commonly accepted in forensic practice.
    """

    st.text_area("Expert Summary", report, height=260)

    if st.button("üß† Explain Like Expert Witness"):
        st.info(
            "These findings indicate intent rather than accident. The alignment of "
            "filesystem inconsistencies, log suppression, and tool traces forms a "
            "coherent forensic narrative."
        )

    st.download_button(
        "‚¨á Download Report (JSON)",
        json.dumps({"risk": risk, "confidence": ai_conf}, indent=4),
        "logtrace_report.json"
    )

# ======================================================
# TAB 6 ‚Äî SIEM / SOC
# ======================================================
with tabs[5]:
    st.subheader("üõ∞Ô∏è SIEM / SOC Integration")

    c1, c2, c3 = st.columns(3)

    with c1:
        st.markdown('<div class="card"><div class="icon">üì°</div><h4>SIEM Ingest</h4>'
                    'Exports JSON to Splunk, ELK, Sentinel</div>', unsafe_allow_html=True)

    with c2:
        st.markdown('<div class="card"><div class="icon">üß†</div><h4>SOC Enrichment</h4>'
                    'Adds MITRE ATT&CK + confidence scores</div>', unsafe_allow_html=True)

    with c3:
        st.markdown('<div class="card"><div class="icon">‚öñÔ∏è</div><h4>Legal Readiness</h4>'
                    'Court-safe reports for IR & compliance</div>', unsafe_allow_html=True)

    st.markdown("""
    ### SOC Workflow Fit
    **EDR ‚Üí SIEM ‚Üí LogTrace AI ‚Üí IR / Legal**
    
    LogTrace AI acts as the *forensic intelligence layer* after alerts are raised.
    """)

# ======================================================
# FOOTER
# ======================================================
st.markdown("---")
st.caption("üõ°Ô∏è LogTrace AI ‚Ä¢ SOC-Ready ‚Ä¢ MITRE-Aligned ‚Ä¢ Court-Defensible")
